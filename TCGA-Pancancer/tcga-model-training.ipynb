{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# TCGA Model training\n",
    "---\n",
    "\n",
    "Experimenting training models on the preprocessed the TCGA dataset from the Pancancer paper (https://www.ncbi.nlm.nih.gov/pubmed/29625048) into a single, clean dataset.\n",
    "\n",
    "The Cancer Genome Atlas (TCGA), a landmark cancer genomics program, molecularly characterized over 20,000 primary cancer and matched normal samples spanning 33 cancer types. This joint effort between the National Cancer Institute and the National Human Genome Research Institute began in 2006, bringing together researchers from diverse disciplines and multiple institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "KOdmFzXqF7nq",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "G5RrWE9R_Nkl"
   },
   "outputs": [],
   "source": [
    "import os                                  # os handles directory/workspace changes\n",
    "import torch                               # PyTorch to create and apply deep learning models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, roc_auc_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Path to the dataset files\n",
    "data_path = 'cleaned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import modin.pandas as pd                  # Optimized distributed version of Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Allow pandas to show more columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Set the random seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tcga_df = pandas.read_csv(f'{data_path}normalized/tcga.csv')\n",
    "tcga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_df.participant_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Remove the original string ID column and use the numeric one instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_df = tcga_df.drop(columns=['participant_id'], axis=1)\n",
    "tcga_df = tcga_df.rename(columns={'Unnamed: 0': 'sample_id'})\n",
    "tcga_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Convert the label to a numeric format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_df.tumor_type_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Encode the categorical labels into numeric values\n",
    "tcga_df['tumor_type_label'], label_array = pandas.factorize(tcga_df['tumor_type_label'])\n",
    "\n",
    "# Create a dictionary mapping integer labels to original string labels\n",
    "label_dict = {i: label for i, label in enumerate(label_array)}\n",
    "\n",
    "# Show value counts of the encoded labels\n",
    "tcga_df['tumor_type_label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Convert to a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_df.dtypes[tcga_df.dtypes == 'object']\n",
    "for col in tcga_df.select_dtypes(include='object').columns:\n",
    "    tcga_df[col] = pandas.factorize(tcga_df[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_df = tcga_df.astype(np.float32)  # or np.float64 if preferred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tcga_tsr = torch.from_numpy(tcga_df.to_numpy())\n",
    "tcga_tsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Step 1: Filter out low-frequency classes (fewer than 10 samples)\n",
    "min_class_samples = 10\n",
    "class_counts = tcga_df['tumor_type_label'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= min_class_samples].index.tolist()\n",
    "filtered_df = tcga_df[tcga_df['tumor_type_label'].isin(valid_classes)].copy()\n",
    "\n",
    "# Step 2: Re-encode labels to 0..K format\n",
    "filtered_df['tumor_type_label'], label_array = pandas.factorize(filtered_df['tumor_type_label'])\n",
    "label_dict = {i: label for i, label in enumerate(label_array)}\n",
    "\n",
    "# Step 3: Convert object columns to numeric\n",
    "for col in filtered_df.select_dtypes(include='object').columns:\n",
    "    filtered_df[col] = pandas.factorize(filtered_df[col])[0]\n",
    "\n",
    "# Step 4: Convert to float32\n",
    "filtered_df = filtered_df.astype(np.float32)\n",
    "\n",
    "# Step 5: Extract features and labels\n",
    "X_all = filtered_df.drop(columns=['tumor_type_label']).to_numpy()\n",
    "y_all = filtered_df['tumor_type_label'].to_numpy().astype(int)\n",
    "\n",
    "# Step 6: Stratified split into train/cal/test (70/10/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all)\n",
    "\n",
    "X_train, X_cal, y_temp_train, y_temp_cal = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp)  # 0.125 of 0.8 = 10%\n",
    "\n",
    "# Step 7: Re-encode training labels and align others to the same mapping\n",
    "y_train, label_array = pandas.factorize(y_temp_train)\n",
    "label_dict = {i: label for i, label in enumerate(label_array)}\n",
    "label_map = {v: i for i, v in enumerate(label_array)}\n",
    "\n",
    "y_cal = np.array([label_map[y] for y in y_temp_cal])\n",
    "y_test = np.array([label_map[y] for y in y_test if y in label_map])\n",
    "X_test = X_test[:len(y_test)]\n",
    "X_cal = X_cal[:len(y_cal)]\n",
    "\n",
    "# Step 8: Apply Truncated SVD to reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_cal_reduced = svd.transform(X_cal)\n",
    "X_test_reduced = svd.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = torch.tensor(X[i:i+batch_size]).float()\n",
    "        y_batch = torch.tensor(y[i:i+batch_size]).long()\n",
    "        yield X_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LDA\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Train LDA\n",
    "lda_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = lda_model.predict(X_test)\n",
    "y_proba = lda_model.predict_proba(X_test)\n",
    "\n",
    "lda_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LDA → Accuracy: {lda_acc:.4f}\")\n",
    "\n",
    "lda_model.fit(X_train_reduced, y_train)\n",
    "y_pred = lda_model.predict(X_test_reduced)\n",
    "lda_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LDA with Dimensionality Reduction → Accuracy: {lda_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QDA\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Train QDA\n",
    "qda_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = qda_model.predict(X_test)\n",
    "y_proba = qda_model.predict_proba(X_test)\n",
    "\n",
    "qda_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"QDA → Accuracy: {qda_acc:.4f}\")\n",
    "\n",
    "qda_model.fit(X_train_reduced, y_train)\n",
    "y_pred = qda_model.predict(X_test_reduced)\n",
    "qda_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"QDA with Dimensionality Reduction → Accuracy: {qda_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFORMAL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.classification import SplitConformalClassifier\n",
    "from mapie.metrics.classification import classification_coverage_score, classification_mean_width_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "# Create SplitConformalClassifier wrapper\n",
    "mapie_lda = SplitConformalClassifier(\n",
    "    estimator=lda_model,\n",
    "    conformity_score=\"aps\",\n",
    "    confidence_level=1 - alpha, \n",
    "    prefit=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Calibrate using reduced calibration set\n",
    "mapie_lda.conformalize(X_cal_reduced, y_cal)\n",
    "\n",
    "# Predict conformal prediction sets on test set\n",
    "_, y_pset_lda = mapie_lda.predict_set(X_test_reduced)\n",
    "\n",
    "# Evaluate coverage and prediction set width\n",
    "coverage_lda = classification_coverage_score(y_test, y_pset_lda)\n",
    "width_lda = classification_mean_width_score(y_pset_lda)\n",
    "\n",
    "print(f\"LDA (APS, alpha={alpha:.2f}) → Coverage: {coverage_lda.item():.4f}, Avg Set Size: {width_lda.item():.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SplitConformalClassifier wrapper\n",
    "mapie_qda = SplitConformalClassifier(\n",
    "    estimator=qda_model,\n",
    "    conformity_score=\"aps\",\n",
    "    confidence_level=1 - alpha, \n",
    "    prefit=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Calibrate using reduced calibration set\n",
    "mapie_qda.conformalize(X_cal_reduced, y_cal)\n",
    "\n",
    "# Predict conformal prediction sets on test set\n",
    "_, y_pset_qda = mapie_qda.predict_set(X_test_reduced)\n",
    "\n",
    "# Evaluate coverage and prediction set width\n",
    "coverage_qda = classification_coverage_score(y_test, y_pset_qda)\n",
    "width_qda = classification_mean_width_score(y_pset_qda)\n",
    "\n",
    "print(f\"QDA (APS, alpha={alpha:.2f}) → Coverage: {coverage_qda.item():.4f}, Avg Set Size: {width_qda.item():.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique labels in y_test:\", len(np.unique(y_test)))\n",
    "print(\"Labels in y_test:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(p, y_true):\n",
    "    y_onehot = np.zeros_like(p)\n",
    "    y_onehot[np.arange(len(y_true)), y_true] = 1\n",
    "    return np.mean(np.sum((y_onehot - p)**2, axis=1))\n",
    "\n",
    "def spherical_score(p, y_true):\n",
    "    norms = np.linalg.norm(p, axis=1)\n",
    "    return np.mean([p[i, y_true[i]] / norms[i] for i in range(len(y_true))])\n",
    "\n",
    "def log_score(p, y_true):\n",
    "    return -np.mean(np.log(p[np.arange(len(y_true)), y_true] + 1e-15))\n",
    "\n",
    "### For LDA\n",
    "probs_lda = lda_model.predict_proba(X_test_reduced)\n",
    "logloss_lda = log_score(probs_lda, y_test)\n",
    "brier_lda = brier_score(probs_lda, y_test)\n",
    "spherical_lda = spherical_score(probs_lda, y_test)\n",
    "\n",
    "print(\"\\nLDA Proper Scoring Rules:\")\n",
    "print(f\"Log Loss:        {logloss_lda:.4f}\")\n",
    "print(f\"Brier Score:     {brier_lda:.4f}\")\n",
    "print(f\"Spherical Score: {spherical_lda:.4f}\")\n",
    "\n",
    "### For QDA\n",
    "probs_qda = qda_model.predict_proba(X_test_reduced)\n",
    "logloss_qda = log_score(probs_qda, y_test)\n",
    "brier_qda = brier_score(probs_qda, y_test)\n",
    "spherical_qda = spherical_score(probs_qda, y_test)\n",
    "\n",
    "print(\"\\nQDA Proper Scoring Rules:\")\n",
    "print(f\"Log Loss:        {logloss_qda:.4f}\")\n",
    "print(f\"Brier Score:     {brier_qda:.4f}\")\n",
    "print(f\"Spherical Score: {spherical_qda:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "tcga-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
