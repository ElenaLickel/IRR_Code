{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy.stats import multivariate_normal\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate data from a ground truth model with K classes and η-dependent covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_per_class, eta, K, means, shared_cov, class_covs):\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for i in range(K):\n",
    "        cov = (1 - eta) * shared_cov + eta * class_covs[i]\n",
    "        X_list.append(np.random.multivariate_normal(means[i], cov, size=n_per_class))\n",
    "        y_list.append(np.full(n_per_class, i))\n",
    "\n",
    "    X = np.vstack(X_list)\n",
    "    y = np.hstack(y_list)\n",
    "\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    perm = rng.permutation(len(y))\n",
    "\n",
    "    return X[perm], y[perm]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base simulation setup\n",
    "- Create smooth class covariance matrices with varying correlations\n",
    "- Correlation smoothly varies between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_simulation(K, eta, n_train, spread=6.0, print_covariances=False):\n",
    "    \"\"\"\n",
    "    Generates well-separated classes with clear covariance differences:\n",
    "    - eta = 0: All classes identical covariance → LDA optimal, QDA overfits\n",
    "    - eta → 1: Classes have very different shapes → QDA better, LDA suboptimal\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create moderately separated, clean centroid arrangement\n",
    "    means = []\n",
    "    if K == 2:\n",
    "        means = [np.array([-2.5, 0.0]), np.array([2.5, 0.0])]\n",
    "    elif K == 3:\n",
    "        # Triangle arrangement for 3 classes - closer together\n",
    "        means = [\n",
    "            np.array([0.0, 2.5]),      # Top\n",
    "            np.array([-2.2, -1.3]),   # Bottom left  \n",
    "            np.array([2.2, -1.3])     # Bottom right\n",
    "        ]\n",
    "    else:\n",
    "        # Regular polygon for K > 3 - smaller radius\n",
    "        angles = np.linspace(0, 2*np.pi, K+1)[:-1]\n",
    "        radius = 3.0\n",
    "        for angle in angles:\n",
    "            means.append(np.array([radius * np.cos(angle), radius * np.sin(angle)]))\n",
    "    \n",
    "    # Shared covariance: this will be the ONLY covariance at eta=0\n",
    "    shared_cov = np.array([[1.2, 0.4],\n",
    "                          [0.4, 1.0]])\n",
    "    \n",
    "    # Class-specific covariances: extremely distinct shapes to hurt LDA more\n",
    "    class_covs = []\n",
    "    \n",
    "    if K >= 1:\n",
    "        # Class 0: Very strong horizontal elongation\n",
    "        class_covs.append(np.array([[4.5, 0.0],\n",
    "                                   [0.0, 0.3]]))\n",
    "    \n",
    "    if K >= 2:\n",
    "        # Class 1: Very strong vertical elongation\n",
    "        class_covs.append(np.array([[0.3, 0.0],\n",
    "                                   [0.0, 4.5]]))\n",
    "    \n",
    "    if K >= 3:\n",
    "        # Class 2: Strong positive diagonal correlation with large spread\n",
    "        class_covs.append(np.array([[2.8, 2.5],\n",
    "                                   [2.5, 2.8]]))\n",
    "    \n",
    "    if K >= 4:\n",
    "        # Class 3: Very strong negative diagonal correlation\n",
    "        class_covs.append(np.array([[2.8, -2.5],\n",
    "                                   [-2.5, 2.8]]))\n",
    "    \n",
    "    if K >= 5:\n",
    "        # Class 4: Extremely small, tight circular - very different scale\n",
    "        class_covs.append(np.array([[0.15, 0.0],\n",
    "                                   [0.0, 0.15]]))\n",
    "    \n",
    "    # For additional classes beyond 5, create systematic patterns\n",
    "    while len(class_covs) < K:\n",
    "        k = len(class_covs)\n",
    "        angle = k * np.pi / 4\n",
    "        cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "        rotation = np.array([[cos_a, -sin_a],\n",
    "                           [sin_a, cos_a]])\n",
    "        \n",
    "        # Alternate between very elongated and very compact\n",
    "        if k % 2 == 0:\n",
    "            base_cov = np.array([[4.0, 0.0], [0.0, 0.25]])\n",
    "        else:\n",
    "            base_cov = np.array([[0.2, 0.0], [0.0, 0.2]])\n",
    "            \n",
    "        rotated_cov = rotation @ base_cov @ rotation.T\n",
    "        class_covs.append(rotated_cov)\n",
    "    \n",
    "    # Ensure all covariances are positive definite\n",
    "    for i in range(len(class_covs)):\n",
    "        class_covs[i] = (class_covs[i] + class_covs[i].T) / 2 + 1e-6 * np.eye(2)\n",
    "    \n",
    "    if print_covariances:\n",
    "        print(f\"Eta = {eta}\")\n",
    "        print(f\"Shared covariance:\\n{shared_cov}\\n\")\n",
    "        for k in range(K):\n",
    "            actual_cov = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "            print(f\"Class {k} centroid: {means[k]}\")\n",
    "            print(f\"Actual covariance matrix:\\n{actual_cov}\")\n",
    "            eigvals = np.linalg.eigvals(actual_cov)\n",
    "            print(f\"Eigenvalues: {eigvals}\")\n",
    "            print(f\"Condition number: {np.max(eigvals)/np.min(eigvals):.2f}\\n\")\n",
    "    \n",
    "    # Generate data\n",
    "    n_per_class = max(1, n_train // K)\n",
    "    X_list, y_list = [], []\n",
    "    for k in range(K):\n",
    "        actual_cov = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        X_k = np.random.multivariate_normal(means[k], actual_cov, size=n_per_class)\n",
    "        y_k = np.full(n_per_class, k)\n",
    "        X_list.append(X_k)\n",
    "        y_list.append(y_k)\n",
    "    \n",
    "    X = np.vstack(X_list)\n",
    "    y = np.hstack(y_list)\n",
    "    \n",
    "    # Shuffle\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    perm = rng.permutation(len(y))\n",
    "    X, y = X[perm], y[perm]\n",
    "    \n",
    "    return X, y, means, shared_cov, class_covs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute Bayes classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayes_predictions(X, means, shared_cov, class_covs, eta):\n",
    "    K = len(means)\n",
    "    n = X.shape[0]\n",
    "    probs = np.zeros((n, K))\n",
    "    priors = np.full(K, 1.0 / K)  # uniform priors\n",
    "\n",
    "\n",
    "    for k in range(K):\n",
    "        sigma_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        sigma_k = (sigma_k + sigma_k.T) / 2  # enforce symmetry\n",
    "        sigma_k += np.eye(sigma_k.shape[0]) * 1e-6  # add epsilon for numerical stability\n",
    "\n",
    "        rv = multivariate_normal(mean=means[k], cov=sigma_k)\n",
    "        probs[:, k] = rv.pdf(X) * priors[k]\n",
    "\n",
    "    probs /= probs.sum(axis=1, keepdims=True)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    return predictions, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def compute_lda_predictions(X_train, y_train, X_test):\n",
    "    model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    return preds, probs, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def compute_qda_predictions(X_train, y_train, X_test):\n",
    "    model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    return preds, probs, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Parameters\n",
    "\n",
    "K = 3\n",
    "eta = 1\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "\n",
    "# Generate train and test data\n",
    "X_train, y_train, means, shared_cov, class_covs = setup_simulation(K, eta, n_train)\n",
    "X_test, y_test, _, _, _ = setup_simulation(K, eta, n_test)\n",
    "\n",
    "# Bayes predictions\n",
    "bayes_preds, bayes_probs = compute_bayes_predictions(X_test, means, shared_cov, class_covs, eta)\n",
    "\n",
    "# LDA predictions\n",
    "lda_preds, lda_probs, lda_model = compute_lda_predictions(X_train, y_train, X_test)\n",
    "\n",
    "# QDA predictions\n",
    "qda_preds, qda_probs, qda_model = compute_qda_predictions(X_train, y_train, X_test)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(name, y_true, y_pred, y_prob):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    ll = log_loss(y_true, y_prob)\n",
    "    print(f\"{name} — Accuracy: {acc:.3f}, Log Loss: {ll:.3f}\")\n",
    "\n",
    "evaluate(\"Bayes\", y_test, bayes_preds, bayes_probs)\n",
    "evaluate(\"LDA\", y_test, lda_preds, lda_probs)\n",
    "evaluate(\"QDA\", y_test, qda_preds, qda_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_lda_decision_boundary(X, y, model, title=\"LDA Decision Boundary\"):\n",
    "    # Create a fine mesh grid over the input space\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Predict class labels over the grid\n",
    "    Z = model.predict(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour and training points\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Set1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qda_decision_boundary(X, y, model, title=\"QDA Decision Boundary\"):\n",
    "    # Create a fine mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Predict class labels over the grid\n",
    "    Z = model.predict(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot contours and training points\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Set1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bayes_decision_boundary(X, y, means, shared_cov, class_covs, eta, title=\"Bayes Decision Boundary\"):\n",
    "    from scipy.stats import multivariate_normal\n",
    "\n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Compute class posteriors manually using true parameters\n",
    "    K = len(means)\n",
    "    priors = np.full(K, 1.0 / K)\n",
    "    probs = np.zeros((grid.shape[0], K))\n",
    "\n",
    "    for k in range(K):\n",
    "        cov_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)  # stabilize\n",
    "        rv = multivariate_normal(mean=means[k], cov=cov_k)\n",
    "        probs[:, k] = rv.pdf(grid) * priors[k]\n",
    "\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    Z = preds.reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Set1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lda_decision_boundary(X_train, y_train, lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qda_decision_boundary(X_train, y_train, qda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bayes_decision_boundary(X_train, y_train, means, shared_cov, class_covs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_boundaries(X, y, lda_model, qda_model, means, shared_cov, class_covs, eta):\n",
    "    from scipy.stats import multivariate_normal\n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),\n",
    "                         np.linspace(y_min, y_max, 500))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Predict class labels\n",
    "    lda_Z = lda_model.predict(grid).reshape(xx.shape)\n",
    "    qda_Z = qda_model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    # Bayes decision\n",
    "    K = len(means)\n",
    "    priors = np.full(K, 1.0 / K)\n",
    "    probs = np.zeros((grid.shape[0], K))\n",
    "\n",
    "    for k in range(K):\n",
    "        cov_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)\n",
    "        rv = multivariate_normal(mean=means[k], cov=cov_k)\n",
    "        probs[:, k] = rv.pdf(grid) * priors[k]\n",
    "    bayes_Z = np.argmax(probs, axis=1).reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Background colours: soft red, blue, green\n",
    "    background_cmap = ListedColormap(['#ffe6e6', '#e6f0ff', '#e6ffe6'])\n",
    "    plt.contourf(xx, yy, bayes_Z, alpha=0.8, cmap=background_cmap)\n",
    "\n",
    "    # Overlay contour lines (decision boundaries)\n",
    "    plt.contour(xx, yy, bayes_Z, colors='grey', linestyles='-', linewidths=2)\n",
    "    plt.contour(xx, yy, lda_Z, colors='orange', linestyles='--', linewidths=1.5)\n",
    "    plt.contour(xx, yy, qda_Z, colors='purple', linestyles='-.', linewidths=1.5)\n",
    "\n",
    "\n",
    "    # Scatter data points: red, blue, green\n",
    "    colors_points = np.array(['red', 'blue', 'green'])\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors_points[y], edgecolor='k', s=40)\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.title(\"LDA vs QDA vs Bayes ($\\\\Sigma_1$ = $\\\\Sigma_2$ = $\\\\Sigma_3$)\")\n",
    "    #plt.title(\"LDA vs QDA vs Bayes ($\\\\Sigma_1$ ≠ $\\\\Sigma_2$ ≠ $\\\\Sigma_3$)\")\n",
    "    plt.xlabel(\"X 1\")\n",
    "    plt.ylabel(\"X 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    custom_lines = [\n",
    "        plt.Line2D([0], [0], color='grey', lw=2, label='Bayes'),\n",
    "        plt.Line2D([0], [0], color='orange', linestyle='--', lw=1.5, label='LDA'), \n",
    "        plt.Line2D([0], [0], color='purple', linestyle='-.', lw=1.5, label='QDA')\n",
    "        ]   \n",
    "    plt.legend(handles=custom_lines)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined_boundaries(X_train, y_train, lda_model, qda_model, means, shared_cov, class_covs, eta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRR_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
