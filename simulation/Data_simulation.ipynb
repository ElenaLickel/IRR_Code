{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy.stats import multivariate_normal\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate data from a ground truth model with K classes and η-dependent covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(n_per_class, eta, K, means, shared_cov, class_covs):\n",
    "    \n",
    "    X_list, y_list = [], [] # Use _list suffix to clearly indicate they are lists of arrays\n",
    "\n",
    "    for i in range(K):\n",
    "        # Calculate the blended covariance matrix based on eta\n",
    "        cov = (1 - eta) * shared_cov + eta * class_covs[i]\n",
    "        \n",
    "        # Add a small epsilon to the diagonal for numerical stability\n",
    "        # This helps prevent LinAlgError due to singular or non-positive definite matrices\n",
    "        #epsilon = 1e-6 \n",
    "        #cov = cov + np.eye(cov.shape[0]) * epsilon\n",
    "        \n",
    "        # Generate multivariate normal samples for the current class\n",
    "        X_list.append(np.random.multivariate_normal(means[i], cov, size=n_per_class))\n",
    "        y_list.append(np.full(n_per_class, i))\n",
    "    \n",
    "    # Vertically stack all class feature arrays into a single data matrix\n",
    "    X = np.vstack(X_list)\n",
    "    # Horizontally stack all class label arrays into a single label vector\n",
    "    y = np.hstack(y_list)\n",
    "    \n",
    "    # Permute the data to ensure samples from different classes are interleaved\n",
    "    # This is important for robust splitting and training\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    perm = rng.permutation(len(y))\n",
    "\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base simulation setup\n",
    "- Create smooth class covariance matrices with varying correlations\n",
    "- Correlation smoothly varies between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_simulation(K, eta, n_train, print_covariances=False):\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Arrange class means in a grid pattern\n",
    "    means = [np.array([i * 2, j * 2])\n",
    "             for i in range(int(np.ceil(K**0.5)))\n",
    "             for j in range(int(np.ceil(K**0.5)))]\n",
    "    means = means[:K]\n",
    "\n",
    "    shared_cov = np.array([[1, 0], [0, 1]])  # Identity\n",
    "    n_per_class = n_train // K\n",
    "\n",
    "    # Generate distinct elliptical and rotated covariances\n",
    "    class_covs = []\n",
    "    for k in range(K):\n",
    "        angle = (np.pi / K) * k  # unique angle per class\n",
    "        rotation = np.array([\n",
    "            [np.cos(angle), -np.sin(angle)],\n",
    "            [np.sin(angle),  np.cos(angle)]\n",
    "        ])\n",
    "        scales = np.diag([1.0 + 0.5 * k, 0.3 + 0.2 * (K - k)])  # different eigenvalues\n",
    "        cov_k = rotation @ scales @ rotation.T\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)  # ensure symmetry & stability\n",
    "        class_covs.append(cov_k)\n",
    "\n",
    "    # Generate data\n",
    "    X_train, y_train = generate_data(n_per_class=n_per_class, eta=eta, K=K,\n",
    "                                     means=means, shared_cov=shared_cov, class_covs=class_covs)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
    "    # Optionally print empirical covariances\n",
    "    if print_covariances:\n",
    "        print(f\"\\nEmpirical covariance matrices (η = {eta}):\")\n",
    "        for i in range(K):\n",
    "            X_class = X_train[y_train == i]\n",
    "            if len(X_class) > 1:\n",
    "                cov = np.cov(X_class, rowvar=False)\n",
    "                print(f\"Class {i}:\\n{cov}\\n\")\n",
    "            else:\n",
    "                print(f\"Class {i}: Not enough samples to compute empirical covariance.\\n\")\n",
    "\n",
    "    return X_train, y_train, means, shared_cov, class_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_simulation_new(K, eta, n_train, print_covariances=False):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    means = [np.array([i * 2, j * 2]) \n",
    "             for i in range(int(np.ceil(K**0.5))) \n",
    "             for j in range(int(np.ceil(K**0.5)))]\n",
    "    means = means[:K]\n",
    "\n",
    "    shared_cov = np.array([[1.0, 0.0], [0.0, 1.0]])  # Keep for Bayes blending\n",
    "    \n",
    "    n_per_class = n_train // K\n",
    "\n",
    "    class_covs = []\n",
    "    for k in range(K):\n",
    "        angle = np.pi / 4 * k  # Distinct rotation for each class\n",
    "        rotation = np.array([\n",
    "            [np.cos(angle), -np.sin(angle)],\n",
    "            [np.sin(angle),  np.cos(angle)]\n",
    "        ])\n",
    "        # Strong anisotropy with different eigenvalues\n",
    "        scales = np.diag([1.0 + k, 0.2 + 0.3 * (K - k)])  \n",
    "        cov_k = rotation @ scales @ rotation.T\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)  # Symmetric & stable\n",
    "        class_covs.append(cov_k)\n",
    "\n",
    "    X_train, y_train = generate_data(\n",
    "        n_per_class=n_per_class,\n",
    "        eta=eta,\n",
    "        K=K,\n",
    "        means=means,\n",
    "        shared_cov=shared_cov,\n",
    "        class_covs=class_covs\n",
    "    )\n",
    "\n",
    "    if print_covariances:\n",
    "        print(f\"\\nEmpirical covariance matrices (η = {eta}):\")\n",
    "        for i in range(K):\n",
    "            X_class = X_train[y_train == i]\n",
    "            cov = np.cov(X_class, rowvar=False)\n",
    "            print(f\"Class {i}:\\n{cov}\\n\")\n",
    "\n",
    "    return X_train, y_train, means, shared_cov, class_covs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute Bayes classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayes_predictions(X, means, shared_cov, class_covs, eta):\n",
    "    K = len(means)\n",
    "    n = X.shape[0]\n",
    "    probs = np.zeros((n, K))\n",
    "    priors = np.full(K, 1.0 / K)  # uniform priors\n",
    "\n",
    "\n",
    "    for k in range(K):\n",
    "        sigma_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        sigma_k = (sigma_k + sigma_k.T) / 2  # enforce symmetry\n",
    "        sigma_k += np.eye(sigma_k.shape[0]) * 1e-6  # add epsilon for numerical stability\n",
    "\n",
    "        rv = multivariate_normal(mean=means[k], cov=sigma_k)\n",
    "        probs[:, k] = rv.pdf(X) * priors[k]\n",
    "\n",
    "    probs /= probs.sum(axis=1, keepdims=True)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    return predictions, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def compute_lda_predictions(X_train, y_train, X_test):\n",
    "    model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    return preds, probs, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def compute_qda_predictions(X_train, y_train, X_test):\n",
    "    model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    return preds, probs, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimate means from training data\n",
    "- Generate test data using the same method (or use part of train data as test)\n",
    "- Estimate shared covariance (pooled estimate for LDA)\n",
    "- Estimate class-specific covariances (for QDA and Bayes)\n",
    "- Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Parameters\n",
    "k = 3\n",
    "eta = 0.1\n",
    "n_train = 20\n",
    "\n",
    "# Generate training data and get true parameters\n",
    "X_train, y_train, means_true, shared_cov_true, class_covs_true = setup_simulation(k, eta, n_train)\n",
    "\n",
    "means_est = [X_train[y_train == k].mean(axis=0) for k in range(k)]\n",
    "shared_cov_est = np.cov(X_train.T)\n",
    "class_covs_est = [np.cov(X_train[y_train == k].T) for k in range(k)]\n",
    "\n",
    "# Generate test data using the same parameters from training\n",
    "n_test_per_class = 25 \n",
    "X_test, y_test = generate_data(n_per_class=n_test_per_class, eta=eta, K=k,\n",
    "                               means=means_true,\n",
    "                               shared_cov=shared_cov_true,\n",
    "                               class_covs=class_covs_true)\n",
    "\n",
    "# Predict using LDA, QDA, and Bayes classifiers\n",
    "preds_lda, probs_lda, lda_model = compute_lda_predictions(X_train, y_train, X_test)\n",
    "preds_qda, probs_qda, qda_model = compute_qda_predictions(X_train, y_train, X_test)\n",
    "preds_bayes, probs_bayes = compute_bayes_predictions(X_test, means_est, shared_cov_est, class_covs_est, eta)\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "print(\"LDA Accuracy:\", accuracy(y_test, preds_lda))\n",
    "print(\"QDA Accuracy:\", accuracy(y_test, preds_qda))\n",
    "print(\"Bayes Accuracy:\", accuracy(y_test, preds_bayes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw confidence ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ellipses(ax, means, shared_cov, class_covs, eta):\n",
    "    for i, mean in enumerate(means):\n",
    "        cov = (1 - eta) * shared_cov + eta * class_covs[i]\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        vals, vecs = vals[order], vecs[:, order]\n",
    "        theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "        width, height = 2 * np.sqrt(5.991 * vals)\n",
    "        ellip = Ellipse(xy=mean, width=width, height=height, angle=theta, edgecolor='black', fc='None', lw=2)\n",
    "        ax.add_patch(ellip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot LDA, QDA, and Bayes boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def visualize_boundaries(X_train, y_train, X_test, y_test,\n",
    "                         means_true, shared_cov_true, class_covs_true,\n",
    "                         means_est, shared_cov_est, class_covs_est,\n",
    "                         preds_lda, preds_qda, preds_bayes,\n",
    "                         lda_model, qda_model, eta):\n",
    "\n",
    "    # Set up mesh grid\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Compute probability predictions instead of class labels\n",
    "    _, _,  lda_model = compute_lda_predictions(X_train, y_train, grid)\n",
    "    _, _,  qda_model = compute_qda_predictions(X_train, y_train, grid)\n",
    "    _, probs_bayes_grid = compute_bayes_predictions(grid, means_est, shared_cov_est, class_covs_est, eta)\n",
    "\n",
    "\n",
    "    Z_lda_prob = lda_model.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "    Z_qda_pred = qda_model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    Z_bayes_prob = probs_bayes_grid[:, 1].reshape(xx.shape)\n",
    "\n",
    "    # Class prediction for background coloring\n",
    "    Z_qda_class = qda_model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.contourf(xx, yy, Z_qda_class, alpha=0.1)\n",
    "\n",
    "    # Plot decision boundaries at p = 0.5\n",
    "    ax.contour(xx, yy, Z_qda_pred, levels=[0.5], colors='green', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_bayes_prob, levels=[0.5], colors='purple', linestyles='--', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_lda_prob, levels=[0.5], colors='black', linestyles=':', linewidths=2)\n",
    "\n",
    "    # Plot test points\n",
    "    for i in range(len(np.unique(y_train))):\n",
    "        ax.scatter(X_test[y_test == i, 0], X_test[y_test == i, 1],\n",
    "                   s=30, label=f\"Class {i}\", alpha=0.6)\n",
    "\n",
    "    # Draw true ellipses\n",
    "    #draw_ellipses(ax, means_true, shared_cov_true, class_covs_true, eta)\n",
    "\n",
    "    # Accuracy scores\n",
    "    def accuracy(y_true, y_pred): return np.mean(y_true == y_pred)\n",
    "    acc_lda = accuracy(y_test, preds_lda)\n",
    "    acc_qda = accuracy(y_test, preds_qda)\n",
    "    acc_bayes = accuracy(y_test, preds_bayes)\n",
    "\n",
    "    # Title and legend\n",
    "    ax.set_title(f\"QDA vs Bayes vs LDA (η = {eta})\\n\"\n",
    "                 f\"LDA: {acc_lda:.2f}, QDA: {acc_qda:.2f}, Bayes: {acc_bayes:.2f}\")\n",
    "    ax.set_xlabel(\"$X_1$\")\n",
    "    ax.set_ylabel(\"$X_2$\")\n",
    "\n",
    "    custom_lines = [Line2D([0], [0], color='green', linestyle='-'),\n",
    "                    Line2D([0], [0], color='purple', linestyle='--'),\n",
    "                    Line2D([0], [0], color='black', linestyle=':')]\n",
    "    ax.legend(custom_lines, ['QDA Boundary', 'Bayes Boundary', 'LDA Boundary'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boundaries(X_train, y_train, X_test, y_test,\n",
    "                         means_true, shared_cov_true, class_covs_true,\n",
    "                         means_est, shared_cov_est, class_covs_est,\n",
    "                         preds_lda, preds_qda, preds_bayes,\n",
    "                         lda_model, qda_model, eta):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    # Set up mesh grid\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Predict class labels over grid\n",
    "    Z_lda = lda_model.predict(grid).reshape(xx.shape)\n",
    "    Z_qda = qda_model.predict(grid).reshape(xx.shape)\n",
    "    Z_bayes, _ = compute_bayes_predictions(grid, means_est, shared_cov_est, class_covs_est, eta)\n",
    "    Z_bayes = Z_bayes.reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Background: QDA class predictions\n",
    "    ax.contourf(xx, yy, Z_qda, alpha=0.1)\n",
    "\n",
    "    # Plot decision boundaries between classes\n",
    "    levels = np.arange(len(np.unique(y_train)) + 1) - 0.5\n",
    "    ax.contour(xx, yy, Z_qda, levels=levels, colors='green', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_bayes, levels=levels, colors='purple', linestyles='--', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_lda, levels=levels, colors='black', linestyles=':', linewidths=2)\n",
    "\n",
    "    # Plot test points\n",
    "    for i in range(len(np.unique(y_train))):\n",
    "        ax.scatter(X_test[y_test == i, 0], X_test[y_test == i, 1],\n",
    "                   s=30, label=f\"Class {i}\", alpha=0.6)\n",
    "\n",
    "    # Accuracy scores\n",
    "    def accuracy(y_true, y_pred): return np.mean(y_true == y_pred)\n",
    "    acc_lda = accuracy(y_test, preds_lda)\n",
    "    acc_qda = accuracy(y_test, preds_qda)\n",
    "    acc_bayes = accuracy(y_test, preds_bayes)\n",
    "\n",
    "    # Title and labels\n",
    "    ax.set_title(f\"QDA vs Bayes vs LDA (η = {eta})\\n\"\n",
    "                 f\"LDA: {acc_lda:.2f}, QDA: {acc_qda:.2f}, Bayes: {acc_bayes:.2f}\")\n",
    "    ax.set_xlabel(\"$X_1$\")\n",
    "    ax.set_ylabel(\"$X_2$\")\n",
    "\n",
    "    # Custom legend\n",
    "    custom_lines = [Line2D([0], [0], color='green', linestyle='-'),\n",
    "                    Line2D([0], [0], color='purple', linestyle='--'),\n",
    "                    Line2D([0], [0], color='black', linestyle=':')]\n",
    "    ax.legend(custom_lines, ['QDA Boundary', 'Bayes Boundary', 'LDA Boundary'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boundaries(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    means_true=means_true,\n",
    "    shared_cov_true=shared_cov_true,\n",
    "    class_covs_true=class_covs_true,\n",
    "    means_est=means_est,\n",
    "    shared_cov_est=shared_cov_est,\n",
    "    class_covs_est=class_covs_est,\n",
    "    preds_lda=preds_lda,\n",
    "    preds_qda=preds_qda,\n",
    "    preds_bayes=preds_bayes,\n",
    "    lda_model=lda_model,\n",
    "    qda_model=qda_model,\n",
    "    eta=eta\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run full simulation, fit, and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(X, pad=1.0):\n",
    "    x_min, x_max = X[:, 0].min() - pad, X[:, 0].max() + pad\n",
    "    y_min, y_max = X[:, 1].min() - pad, X[:, 1].max() + pad\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    return np.c_[xx.ravel(), yy.ravel()], xx, yy\n",
    "\n",
    "def plot_ellipses_and_lda_vs_bayes(K=3, eta=0.0, n_train=20):\n",
    "    X, y, means, shared_cov, class_covs = setup_simulation(K, eta, n_train)\n",
    "    lda = LinearDiscriminantAnalysis().fit(X, y)\n",
    "    grid, xx, yy = make_grid(X)\n",
    "\n",
    "    Z_lda = lda.predict(grid).reshape(xx.shape)\n",
    "    Z_bayes, _ = compute_bayes_predictions(grid, means, shared_cov, class_covs, eta)\n",
    "    Z_bayes = Z_bayes.reshape(xx.shape)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].contourf(xx, yy, Z_bayes, alpha=0.1)\n",
    "    draw_ellipses(axs[0], means, shared_cov, class_covs, eta)\n",
    "    axs[0].contour(xx, yy, Z_bayes, colors='k', linestyles='dashed')\n",
    "    axs[0].set_title(\"Ellipses & Bayes Boundary\")\n",
    "\n",
    "    axs[1].contourf(xx, yy, Z_lda, alpha=0.1)\n",
    "    axs[1].contour(xx, yy, Z_bayes, colors='k', linestyles='dashed')\n",
    "    axs[1].contour(xx, yy, Z_lda, colors='k')\n",
    "    for i in range(K):\n",
    "        axs[1].scatter(X[y == i, 0], X[y == i, 1], s=30)\n",
    "    axs[1].set_title(\"LDA vs Bayes\")\n",
    "\n",
    "    custom_lines = [Line2D([0], [0], color='black', linestyle='-'),\n",
    "                    Line2D([0], [0], color='black', linestyle='dashed')]\n",
    "    axs[1].legend(custom_lines, ['LDA Boundary', 'Bayes Boundary'], loc='upper right')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"$X_1$\")\n",
    "        ax.set_ylabel(\"$X_2$\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_qda_vs_bayes_vs_lda(K=2, n_train=100):\n",
    "    for eta, title in zip([0.0, 1.0], [\"Σ₁ = Σ₂\", \"Σ₁ ≠ Σ₂\"]):\n",
    "        X, y, means, shared_cov, class_covs = setup_simulation(K, eta, n_train)\n",
    "        lda = LinearDiscriminantAnalysis().fit(X, y)\n",
    "        qda = QuadraticDiscriminantAnalysis().fit(X, y)\n",
    "        grid, xx, yy = make_grid(X)\n",
    "\n",
    "        # Compute class 1 probabilities\n",
    "        Z_lda_prob = lda.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "        Z_qda_prob = qda.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "        Z_bayes_prob, _ = compute_bayes_predictions(grid, means, shared_cov, class_covs, eta)\n",
    "        Z_bayes_prob = Z_bayes_prob.reshape(xx.shape)\n",
    "\n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize=(8,15))\n",
    "\n",
    "        # Background coloring by predicted QDA class\n",
    "        Z_qda_class = qda.predict(grid).reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z_qda_class, alpha=0.1)\n",
    "\n",
    "        # True decision boundaries (at p=0.5)\n",
    "        ax.contour(xx, yy, Z_qda_prob, levels=[0.5], colors='green', linewidths=2)\n",
    "        ax.contour(xx, yy, Z_bayes_prob, levels=[0.5], colors='purple', linestyles='--', linewidths=2)\n",
    "        ax.contour(xx, yy, Z_lda_prob, levels=[0.5], colors='black', linestyles=':', linewidths=2)\n",
    "\n",
    "        # Scatter training points\n",
    "        for i in range(K):\n",
    "            ax.scatter(X[y == i, 0], X[y == i, 1], s=30)\n",
    "\n",
    "        ax.set_title(f\"QDA vs Bayes vs LDA ($\\\\Sigma_1$ {('=' if eta==0 else '≠')} $\\\\Sigma_2$)\")\n",
    "        ax.set_xlabel(\"$X_1$\")\n",
    "        ax.set_ylabel(\"$X_2$\")\n",
    "        ax.legend([\n",
    "            Line2D([0], [0], color='green', linewidth=2),\n",
    "            Line2D([0], [0], color='purple', linestyle='--', linewidth=2),\n",
    "            Line2D([0], [0], color='black', linestyle=':', linewidth=2)\n",
    "        ], ['QDA Boundary', 'Bayes Boundary', 'LDA Boundary'], loc='upper right')\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_qda_vs_bayes_vs_lda_general(K=3, n_train=100, eta=0.5):\n",
    "    sns.set_context(\"notebook\", font_scale=1.2)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Simulate data\n",
    "    X, y, means, shared_cov, class_covs = setup_simulation(K, eta, n_train)\n",
    "    \n",
    "    # Fit models\n",
    "    lda = LinearDiscriminantAnalysis().fit(X, y)\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(X, y)\n",
    "    \n",
    "    # Generate grid\n",
    "    grid, xx, yy = make_grid(X)\n",
    "\n",
    "    # Get predicted classes for decision boundaries\n",
    "    Z_lda_class = lda.predict(grid).reshape(xx.shape)\n",
    "    Z_qda_class = qda.predict(grid).reshape(xx.shape)\n",
    "    Z_bayes_class, _ = compute_bayes_predictions(grid, means, shared_cov, class_covs, eta)\n",
    "    Z_bayes_class = Z_bayes_class.reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 25)) \n",
    "\n",
    "    \n",
    "    # QDA background coloring\n",
    "    ax.contourf(xx, yy, Z_qda_class, alpha=0.1, cmap=\"Pastel1\")\n",
    "\n",
    "    # Decision boundaries: contour lines where class changes\n",
    "    levels = np.arange(K + 1) - 0.5\n",
    "    ax.contour(xx, yy, Z_qda_class, levels=levels, colors='green', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_bayes_class, levels=levels, colors='purple', linestyles='--', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_lda_class, levels=levels, colors='black', linestyles=':', linewidths=2)\n",
    "\n",
    "    # Training points\n",
    "    colors = sns.color_palette(\"Set1\", K)\n",
    "    for i in range(K):\n",
    "        ax.scatter(X[y == i, 0], X[y == i, 1], s=40,\n",
    "                   label=f\"Class {i}\", color=colors[i], edgecolor='k', alpha=0.8)\n",
    "\n",
    "    # Title and labels\n",
    "    eq_sign = '=' if eta == 0.0 else '≠'\n",
    "    ax.set_title(f\"QDA vs Bayes vs LDA ($\\\\Sigma_1$ {eq_sign} $\\\\Sigma_2$)\", fontsize=14)\n",
    "    ax.set_xlabel(\"$X_1$\")\n",
    "    ax.set_ylabel(\"$X_2$\")\n",
    "\n",
    "    # Legends\n",
    "    boundary_lines = [\n",
    "        Line2D([0], [0], color='green', lw=2),\n",
    "        Line2D([0], [0], color='purple', linestyle='--', lw=2),\n",
    "        Line2D([0], [0], color='black', linestyle=':', lw=2)\n",
    "    ]\n",
    "    class_dots = [Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor=colors[i], markeredgecolor='k', markersize=10)\n",
    "                  for i in range(K)]\n",
    "\n",
    "    ax.legend(boundary_lines + class_dots,\n",
    "              ['QDA Boundary', 'Bayes Boundary', 'LDA Boundary'] + [f'Class {i}' for i in range(K)],\n",
    "              loc='upper right', frameon=True)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run both plots\n",
    "plot_ellipses_and_lda_vs_bayes(K=3, eta=0.0, n_train=20)\n",
    "plot_qda_vs_bayes_vs_lda(K=3, n_train=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qda_vs_bayes_vs_lda_general(K=3, n_train=20, eta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "def show_decision_boundaries(K=2, eta=0.5, n_train=50):\n",
    "    # Simulate data\n",
    "    X, y, means, shared_cov, class_covs = setup_simulation(K, eta, n_train)\n",
    "\n",
    "    # Fit LDA and QDA\n",
    "    lda = LinearDiscriminantAnalysis().fit(X, y)\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(X, y)\n",
    "\n",
    "    # Grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Get probabilities\n",
    "    Z_lda_prob = lda.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "    Z_qda_prob = qda.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "    Z_bayes_prob, _ = compute_bayes_predictions(grid, means, shared_cov, class_covs, eta)\n",
    "    Z_bayes_prob = Z_bayes_prob.reshape(xx.shape)\n",
    "\n",
    "    # Get class prediction for background\n",
    "    Z_qda_class = qda.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.contourf(xx, yy, Z_qda_class, alpha=0.1)\n",
    "\n",
    "    ax.contour(xx, yy, Z_qda_prob, levels=[0.5], colors='green', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_bayes_prob, levels=[0.5], colors='purple', linestyles='--', linewidths=2)\n",
    "    ax.contour(xx, yy, Z_lda_prob, levels=[0.5], colors='black', linestyles=':', linewidths=2)\n",
    "\n",
    "    for i in range(K):\n",
    "        ax.scatter(X[y == i, 0], X[y == i, 1], s=30, alpha=0.6, label=f\"Class {i}\")\n",
    "\n",
    "    ax.set_title(f\"QDA vs Bayes vs LDA (η = {eta})\")\n",
    "    ax.set_xlabel(\"$X_1$\")\n",
    "    ax.set_ylabel(\"$X_2$\")\n",
    "\n",
    "    custom_lines = [Line2D([0], [0], color='green', linewidth=2),\n",
    "                    Line2D([0], [0], color='purple', linestyle='--', linewidth=2),\n",
    "                    Line2D([0], [0], color='black', linestyle=':', linewidth=2)]\n",
    "    ax.legend(custom_lines, ['QDA Boundary', 'Bayes Boundary', 'LDA Boundary'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_decision_boundaries(K=2, eta=0.0, n_train=50)\n",
    "show_decision_boundaries(K=2, eta=0.5, n_train=50)\n",
    "show_decision_boundaries(K=2, eta=1.0, n_train=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_simulated_data(X, y, title=\"Simulated Data\"):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for c in classes:\n",
    "        plt.scatter(X[y == c, 0], X[y == c, 1], label=f\"Class {c}\", alpha=0.5)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Simulation parameters\n",
    "k = 2\n",
    "eta = 1.0\n",
    "n_train_per_c = 50\n",
    "n_cal_per_c = 25\n",
    "n_test_per_c = 25\n",
    "total_per_class = n_train_per_c + n_cal_per_c + n_test_per_c\n",
    "\n",
    "# Setup simulation (generates initial data + parameters)\n",
    "_, _, means, shared_cov, class_covs = setup_simulation(\n",
    "    K=k,\n",
    "    eta=eta,\n",
    "    n_train=n_train_per_c\n",
    ")\n",
    "\n",
    "# Generate new data with same parameters (larger set)\n",
    "X_full, y_full = generate_data(\n",
    "    n_per_class=total_per_class,\n",
    "    eta=eta,\n",
    "    K=k,\n",
    "    means=means,\n",
    "    shared_cov=shared_cov,\n",
    "    class_covs=class_covs\n",
    ")\n",
    "\n",
    "# Plot the result\n",
    "plot_simulated_data(X_full, y_full, title=f\"Simulated Data (η = {eta:.1f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in np.unique(y_full):\n",
    "    emp_cov = np.cov(X_full[y_full == cls].T)\n",
    "    print(f\"Class {cls} covariance:\\n{emp_cov}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRR_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
