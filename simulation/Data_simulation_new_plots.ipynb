{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy.stats import multivariate_normal\n",
    "np.random.seed(1)\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate data from a ground truth model with K classes and η-dependent covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(n_per_class, eta, K, means, shared_cov, class_covs):\n",
    "    \n",
    "    X_list, y_list = [], [] # Use _list suffix to clearly indicate they are lists of arrays\n",
    "\n",
    "    for i in range(K):\n",
    "        # Calculate the blended covariance matrix based on eta\n",
    "        cov = (1 - eta) * shared_cov + eta * class_covs[i]\n",
    "        \n",
    "        # Add a small epsilon to the diagonal for numerical stability\n",
    "        # This helps prevent LinAlgError due to singular or non-positive definite matrices\n",
    "        #epsilon = 1e-6 \n",
    "        #cov = cov + np.eye(cov.shape[0]) * epsilon\n",
    "        \n",
    "        # Generate multivariate normal samples for the current class\n",
    "        X_list.append(np.random.multivariate_normal(means[i], cov, size=n_per_class))\n",
    "        y_list.append(np.full(n_per_class, i))\n",
    "    \n",
    "    # Vertically stack all class feature arrays into a single data matrix\n",
    "    X = np.vstack(X_list)\n",
    "    # Horizontally stack all class label arrays into a single label vector\n",
    "    y = np.hstack(y_list)\n",
    "    \n",
    "    # Permute the data to ensure samples from different classes are interleaved\n",
    "    # This is important for robust splitting and training\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    perm = rng.permutation(len(y))\n",
    "\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base simulation setup\n",
    "- Create smooth class covariance matrices with varying correlations\n",
    "- Correlation smoothly varies between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_simulation(K, eta, n_train, print_covariances=False):\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Arrange class means in a grid pattern\n",
    "    means = [np.array([i * 2, j * 2])\n",
    "             for i in range(int(np.ceil(K**0.5)))\n",
    "             for j in range(int(np.ceil(K**0.5)))]\n",
    "    means = means[:K]\n",
    "\n",
    "    shared_cov = np.array([[1, 0], [0, 1]])  # Identity\n",
    "    n_per_class = n_train // K\n",
    "\n",
    "    # Generate distinct elliptical and rotated covariances\n",
    "    class_covs = []\n",
    "    for k in range(K):\n",
    "        angle = (np.pi / K) * k  # unique angle per class\n",
    "        rotation = np.array([\n",
    "            [np.cos(angle), -np.sin(angle)],\n",
    "            [np.sin(angle),  np.cos(angle)]\n",
    "        ])\n",
    "        scales = np.diag([1.0 + 0.5 * k, 0.3 + 0.2 * (K - k)])  # different eigenvalues\n",
    "        cov_k = rotation @ scales @ rotation.T\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)  # ensure symmetry & stability\n",
    "        class_covs.append(cov_k)\n",
    "\n",
    "    # Generate data\n",
    "    X_train, y_train = generate_data(n_per_class=n_per_class, eta=eta, K=K,\n",
    "                                     means=means, shared_cov=shared_cov, class_covs=class_covs)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
    "    # Optionally print empirical covariances\n",
    "    if print_covariances:\n",
    "        print(f\"\\nEmpirical covariance matrices (η = {eta}):\")\n",
    "        for i in range(K):\n",
    "            X_class = X_train[y_train == i]\n",
    "            if len(X_class) > 1:\n",
    "                cov = np.cov(X_class, rowvar=False)\n",
    "                print(f\"Class {i}:\\n{cov}\\n\")\n",
    "            else:\n",
    "                print(f\"Class {i}: Not enough samples to compute empirical covariance.\\n\")\n",
    "\n",
    "    return X_train, y_train, means, shared_cov, class_covs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute Bayes classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayes_predictions(X, means, shared_cov, class_covs, eta):\n",
    "    K = len(means)\n",
    "    n = X.shape[0]\n",
    "    probs = np.zeros((n, K))\n",
    "    priors = np.full(K, 1.0 / K)  # uniform priors\n",
    "\n",
    "\n",
    "    for k in range(K):\n",
    "        sigma_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        sigma_k = (sigma_k + sigma_k.T) / 2  # enforce symmetry\n",
    "        sigma_k += np.eye(sigma_k.shape[0]) * 1e-6  # add epsilon for numerical stability\n",
    "\n",
    "        rv = multivariate_normal(mean=means[k], cov=sigma_k)\n",
    "        probs[:, k] = rv.pdf(X) * priors[k]\n",
    "\n",
    "    probs /= probs.sum(axis=1, keepdims=True)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    return predictions, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def compute_lda_predictions(X_train, y_train, X_test):\n",
    "    model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    return preds, probs, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def compute_qda_predictions(X_train, y_train, X_test):\n",
    "    model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    return preds, probs, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "K = 3\n",
    "eta = 0\n",
    "n_train = 200\n",
    "n_test = 50\n",
    "\n",
    "# Generate train and test data\n",
    "X_train, y_train, means, shared_cov, class_covs = setup_simulation(K, eta, n_train)\n",
    "X_test, y_test, _, _, _ = setup_simulation(K, eta, n_test)\n",
    "\n",
    "# Bayes predictions\n",
    "bayes_preds, bayes_probs = compute_bayes_predictions(X_test, means, shared_cov, class_covs, eta)\n",
    "\n",
    "# LDA predictions\n",
    "lda_preds, lda_probs, lda_model = compute_lda_predictions(X_train, y_train, X_test)\n",
    "\n",
    "# QDA predictions\n",
    "qda_preds, qda_probs, qda_model = compute_qda_predictions(X_train, y_train, X_test)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(name, y_true, y_pred, y_prob):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    ll = log_loss(y_true, y_prob)\n",
    "    print(f\"{name} — Accuracy: {acc:.3f}, Log Loss: {ll:.3f}\")\n",
    "\n",
    "evaluate(\"Bayes\", y_test, bayes_preds, bayes_probs)\n",
    "evaluate(\"LDA\", y_test, lda_preds, lda_probs)\n",
    "evaluate(\"QDA\", y_test, qda_preds, qda_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_lda_decision_boundary(X, y, model, title=\"LDA Decision Boundary\"):\n",
    "    # Create a fine mesh grid over the input space\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Predict class labels over the grid\n",
    "    Z = model.predict(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour and training points\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Set1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qda_decision_boundary(X, y, model, title=\"QDA Decision Boundary\"):\n",
    "    # Create a fine mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Predict class labels over the grid\n",
    "    Z = model.predict(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot contours and training points\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Set1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bayes_decision_boundary(X, y, means, shared_cov, class_covs, eta, title=\"Bayes Decision Boundary\"):\n",
    "    from scipy.stats import multivariate_normal\n",
    "\n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Compute class posteriors manually using true parameters\n",
    "    K = len(means)\n",
    "    priors = np.full(K, 1.0 / K)\n",
    "    probs = np.zeros((grid.shape[0], K))\n",
    "\n",
    "    for k in range(K):\n",
    "        cov_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)  # stabilize\n",
    "        rv = multivariate_normal(mean=means[k], cov=cov_k)\n",
    "        probs[:, k] = rv.pdf(grid) * priors[k]\n",
    "\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    Z = preds.reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Set1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lda_decision_boundary(X_train, y_train, lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qda_decision_boundary(X_train, y_train, qda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bayes_decision_boundary(X_train, y_train, means, shared_cov, class_covs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_boundaries(X, y, lda_model, qda_model, means, shared_cov, class_covs, eta):\n",
    "    from scipy.stats import multivariate_normal\n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),\n",
    "                         np.linspace(y_min, y_max, 500))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Predict class labels\n",
    "    lda_Z = lda_model.predict(grid).reshape(xx.shape)\n",
    "    qda_Z = qda_model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    # Bayes decision\n",
    "    K = len(means)\n",
    "    priors = np.full(K, 1.0 / K)\n",
    "    probs = np.zeros((grid.shape[0], K))\n",
    "\n",
    "    for k in range(K):\n",
    "        cov_k = (1 - eta) * shared_cov + eta * class_covs[k]\n",
    "        cov_k = (cov_k + cov_k.T) / 2 + 1e-6 * np.eye(2)\n",
    "        rv = multivariate_normal(mean=means[k], cov=cov_k)\n",
    "        probs[:, k] = rv.pdf(grid) * priors[k]\n",
    "    bayes_Z = np.argmax(probs, axis=1).reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Background colours: soft red, blue, green\n",
    "    background_cmap = ListedColormap(['#ffe6e6', '#e6f0ff', '#e6ffe6'])\n",
    "    plt.contourf(xx, yy, bayes_Z, alpha=0.8, cmap=background_cmap)\n",
    "\n",
    "    # Overlay contour lines (decision boundaries)\n",
    "    plt.contour(xx, yy, bayes_Z, colors='grey', linestyles='-', linewidths=2)\n",
    "    plt.contour(xx, yy, lda_Z, colors='orange', linestyles='--', linewidths=1.5)\n",
    "    plt.contour(xx, yy, qda_Z, colors='purple', linestyles='-.', linewidths=1.5)\n",
    "\n",
    "\n",
    "    # Scatter data points: red, blue, green\n",
    "    colors_points = np.array(['red', 'blue', 'green'])\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors_points[y], edgecolor='k', s=40)\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.title(\"LDA vs QDA vs Bayes ($\\\\Sigma_1$ = $\\\\Sigma_2$ = $\\\\Sigma_3$)\")\n",
    "    #plt.title(\"LDA vs QDA vs Bayes ($\\\\Sigma_1$ ≠ $\\\\Sigma_2$ ≠ $\\\\Sigma_3$)\")\n",
    "    plt.xlabel(\"X 1\")\n",
    "    plt.ylabel(\"X 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    custom_lines = [\n",
    "        plt.Line2D([0], [0], color='grey', lw=2, label='Bayes'),\n",
    "        plt.Line2D([0], [0], color='orange', linestyle='--', lw=1.5, label='LDA'), \n",
    "        plt.Line2D([0], [0], color='purple', linestyle='-.', lw=1.5, label='QDA')\n",
    "        ]   \n",
    "    plt.legend(handles=custom_lines)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined_boundaries(X_train, y_train, lda_model, qda_model, means, shared_cov, class_covs, eta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRR_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
