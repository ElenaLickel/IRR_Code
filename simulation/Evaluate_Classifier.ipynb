{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.integrate import nquad\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "from simulation_utils import (\n",
    "    setup_simulation,\n",
    "    generate_data,\n",
    "    compute_bayes_predictions,\n",
    "    compute_lda_predictions,\n",
    "    compute_qda_predictions\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from simulation_utils import setup_simulation, generate_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters and Simulate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3  \n",
    "n_per_class = 100\n",
    "etas = np.linspace(0, 1, 5)\n",
    "n_values = [100, 200, 500, 1000, 5000]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(p, y_true):\n",
    "    y_onehot = np.zeros_like(p)\n",
    "    y_onehot[np.arange(len(y_true)), y_true] = 1\n",
    "    return np.mean(np.sum((y_onehot - p)**2, axis=1))\n",
    "\n",
    "def spherical_score(p, y_true):\n",
    "    norms = np.linalg.norm(p, axis=1)\n",
    "    return np.mean([p[i, y_true[i]] / norms[i] for i in range(len(y_true))])\n",
    "\n",
    "def log_score(p, y_true):\n",
    "    return -np.mean([np.log(p[i, y_true[i]] + 1e-15) for i in range(len(y_true))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in etas:\n",
    "    for n_train in n_values:\n",
    "        X_train, y_train, means, shared_cov, class_covs = setup_simulation(K=k, eta=eta, n_train=n_train)\n",
    "\n",
    "        X_test, y_test = generate_data( n_per_class=n_per_class, eta=eta, K=k, means=means, shared_cov=shared_cov, class_covs=class_covs)\n",
    "\n",
    "        # --- Fit models ---\n",
    "        lda = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "        qda = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "        # --- Predict ---\n",
    "        y_pred_lda = lda.predict(X_test)\n",
    "        y_pred_qda = qda.predict(X_test)\n",
    "        p_lda = lda.predict_proba(X_test)\n",
    "        p_qda = qda.predict_proba(X_test)\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        results.append((\n",
    "            eta, n_train,\n",
    "            accuracy_score(y_test, y_pred_lda),\n",
    "            accuracy_score(y_test, y_pred_qda),\n",
    "            brier_score(p_lda, y_test),\n",
    "            brier_score(p_qda, y_test),\n",
    "            log_score(p_lda, y_test),\n",
    "            log_score(p_qda, y_test),\n",
    "            spherical_score(p_lda, y_test),\n",
    "            spherical_score(p_qda, y_test)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'eta', 'n_train',\n",
    "    'acc_lda', 'acc_qda',\n",
    "    'brier_lda', 'brier_qda',\n",
    "    'log_lda', 'log_qda',\n",
    "    'spherical_lda', 'spherical_qda'\n",
    "]\n",
    "df_results = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for specific simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "eta = 0\n",
    "n_train = 100\n",
    "n_per_class = 50\n",
    "\n",
    "X_train, y_train, means, shared_cov, class_covs = setup_simulation(K=k, eta=eta, n_train=n_train)\n",
    "X_test, y_test = generate_data( n_per_class=n_per_class, eta=eta, K=k, means=means, shared_cov=shared_cov, class_covs=class_covs)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "qda = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "y_pred_qda = qda.predict(X_test)\n",
    "p_lda = lda.predict_proba(X_test)\n",
    "p_qda = qda.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy - LDA:\", accuracy_score(y_test, y_pred_lda))\n",
    "print(\"Accuracy - QDA:\", accuracy_score(y_test, y_pred_qda))\n",
    "\n",
    "print(\"Brier - LDA:\", brier_score(p_lda, y_test))\n",
    "print(\"Brier - QDA:\", brier_score(p_qda, y_test))\n",
    "\n",
    "print(\"Log - LDA:\", log_score(p_lda, y_test))\n",
    "print(\"Log - QDA:\", log_score(p_qda, y_test))\n",
    "\n",
    "print(\"Spherical - LDA:\", spherical_score(p_lda, y_test))\n",
    "print(\"Spherical - QDA:\", spherical_score(p_qda, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_scores, qda_scores = [], []\n",
    "\n",
    "for seed in range(100):\n",
    "    np.random.seed(seed)\n",
    "    X_train, y_train, means, shared_cov, class_covs = setup_simulation(K=3, eta=0.0, n_train=100)\n",
    "    X_test, y_test = generate_data(n_per_class=50, eta=0.0, K=3, means=means, shared_cov=shared_cov, class_covs=class_covs)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "    acc_lda = accuracy_score(y_test, lda.predict(X_test))\n",
    "    acc_qda = accuracy_score(y_test, qda.predict(X_test))\n",
    "\n",
    "    lda_scores.append(acc_lda)\n",
    "    qda_scores.append(acc_qda)\n",
    "\n",
    "print(\"Avg LDA:\", np.mean(lda_scores))\n",
    "print(\"Avg QDA:\", np.mean(qda_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRR_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
